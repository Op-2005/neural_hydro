2025-12-03 01:56:13,181: Logging to runs/lstm_camels_us_0312_015613/output.log initialized.
2025-12-03 01:56:13,181: ### Folder structure created at runs/lstm_camels_us_0312_015613
2025-12-03 01:56:13,181: ### Run configurations for lstm_camels_us
2025-12-03 01:56:13,181: experiment_name: lstm_camels_us
2025-12-03 01:56:13,181: run_dir: runs/lstm_camels_us_0312_015613
2025-12-03 01:56:13,182: train_basin_file: experiments/1_basin.txt
2025-12-03 01:56:13,182: validation_basin_file: experiments/1_basin.txt
2025-12-03 01:56:13,182: test_basin_file: experiments/1_basin.txt
2025-12-03 01:56:13,182: train_start_date: 1990-01-01 00:00:00
2025-12-03 01:56:13,182: train_end_date: 1999-12-31 00:00:00
2025-12-03 01:56:13,182: validation_start_date: 2000-01-01 00:00:00
2025-12-03 01:56:13,182: validation_end_date: 2004-12-31 00:00:00
2025-12-03 01:56:13,182: test_start_date: 2005-01-01 00:00:00
2025-12-03 01:56:13,182: test_end_date: 2010-12-31 00:00:00
2025-12-03 01:56:13,182: device: cpu
2025-12-03 01:56:13,182: validate_every: 1
2025-12-03 01:56:13,182: validate_n_random_basins: 1
2025-12-03 01:56:13,182: metrics: ['NSE']
2025-12-03 01:56:13,182: model: lstm
2025-12-03 01:56:13,182: head: regression
2025-12-03 01:56:13,182: output_activation: linear
2025-12-03 01:56:13,182: hidden_size: 64
2025-12-03 01:56:13,182: initial_forget_bias: 3
2025-12-03 01:56:13,182: output_dropout: 0.4
2025-12-03 01:56:13,182: optimizer: Adam
2025-12-03 01:56:13,182: loss: MSE
2025-12-03 01:56:13,182: learning_rate: {0: 0.001}
2025-12-03 01:56:13,182: batch_size: 128
2025-12-03 01:56:13,182: epochs: 5
2025-12-03 01:56:13,182: clip_gradient_norm: 1
2025-12-03 01:56:13,182: predict_last_n: 1
2025-12-03 01:56:13,183: seq_length: 30
2025-12-03 01:56:13,183: num_workers: 4
2025-12-03 01:56:13,183: log_interval: 5
2025-12-03 01:56:13,183: log_tensorboard: False
2025-12-03 01:56:13,183: dataset: camels_us
2025-12-03 01:56:13,183: data_dir: datasets/camels_us
2025-12-03 01:56:13,183: forcings: ['maurer']
2025-12-03 01:56:13,183: dynamic_inputs: ['prcp(mm/day)', 'srad(W/m2)', 'tmax(C)', 'tmin(C)', 'vp(Pa)']
2025-12-03 01:56:13,183: target_variables: ['QObs(mm/d)']
2025-12-03 01:56:13,183: clip_targets_to_zero: ['QObs(mm/d)']
2025-12-03 01:56:13,183: static_attributes: ['elev_mean', 'area_gages2', 'slope_mean', 'p_mean', 'pet_mean']
2025-12-03 01:56:13,183: number_of_basins: 1
2025-12-03 01:56:13,183: train_dir: runs/lstm_camels_us_0312_015613/train_data
2025-12-03 01:56:13,183: img_log_dir: runs/lstm_camels_us_0312_015613/img_log
2025-12-03 01:56:13,184: ### Device cpu will be used for training
2025-12-03 01:56:13,217: Uncaught exception
Traceback (most recent call last):
  File "/Applications/anaconda3/envs/nh/bin/nh-run", line 7, in <module>
    sys.exit(_main())
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/nh_run.py", line 43, in _main
    start_run(config_file=Path(args["config_file"]), gpu=args["gpu"])
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/nh_run.py", line 77, in start_run
    start_training(config)
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/training/train.py", line 19, in start_training
    trainer.initialize_training()
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/training/basetrainer.py", line 154, in initialize_training
    ds = self._get_dataset()
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/training/basetrainer.py", line 87, in _get_dataset
    return get_dataset(cfg=self.cfg, period="train", is_train=True, scaler=self._scaler)
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/datasetzoo/__init__.py", line 71, in get_dataset
    return _datasetZooRegistry.instantiate_dataset(cfg, is_train, period, basin, additional_features, id_to_int, scaler)
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/datasetzoo/datasetregistry.py", line 92, in instantiate_dataset
    return Dataset(cfg=cfg,
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/datasetzoo/camelsus.py", line 60, in __init__
    super(CamelsUS, self).__init__(cfg=cfg,
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/datasetzoo/basedataset.py", line 142, in __init__
    self._load_data()
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/datasetzoo/basedataset.py", line 745, in _load_data
    self._load_combined_attributes()
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/datasetzoo/basedataset.py", line 703, in _load_combined_attributes
    utils.attributes_sanity_check(df=df)
  File "/Users/om/Desktop/neural_hydrology/neuralhydrology/datautils/utils.py", line 174, in attributes_sanity_check
    raise RuntimeError("".join(msg))
RuntimeError: The following attributes have a std of zero or NaN, which results in NaN's when normalizing the features. Remove the attributes from the attribute feature list and restart the run. 
Attributes: ['elev_mean', 'area_gages2', 'slope_mean', 'p_mean', 'pet_mean']
