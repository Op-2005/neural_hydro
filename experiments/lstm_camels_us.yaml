# ---------------------------
# Experiment configuration
# ---------------------------
experiment_name: lstm_camels_us
run_dir: runs/

# ---------------------------
# Basin selection
# ---------------------------
train_basin_file: ./experiments/1_basin.txt
validation_basin_file: ./experiments/1_basin.txt
test_basin_file: ./experiments/1_basin.txt

# ---------------------------
# Date ranges (dd/mm/yyyy)
# ---------------------------
train_start_date: "01/01/1990"
train_end_date:   "31/12/1999"

validation_start_date: "01/01/2000"
validation_end_date:   "31/12/2004"

test_start_date: "01/01/2005"
test_end_date:   "31/12/2010"

device: cpu   # OR cuda:0 if torch works

# ---------------------------
# Validation
# ---------------------------
validate_every: 1
validate_n_random_basins: 1
metrics:
  - NSE

# ---------------------------
# Model
# ---------------------------
model: lstm
head: regression
output_activation: linear
hidden_size: 64
initial_forget_bias: 3
output_dropout: 0.4

# ---------------------------
# Training
# ---------------------------
optimizer: Adam
loss: MSE
learning_rate:
  0: 1e-3

batch_size: 32
epochs: 5
clip_gradient_norm: 1
predict_last_n: 1
seq_length: 30
num_workers: 4
log_interval: 5
log_tensorboard: False

# ---------------------------
# Dataset
# ---------------------------
dataset: camels_us
data_dir: ./datasets/camels_us

forcings:
  - maurer

dynamic_inputs:
  - PRCP(mm/day)
  - SRAD(W/m2)
  - Tmax(C)
  - Tmin(C)
  - Vp(Pa)


target_variables:
  - QObs(mm/d)

clip_targets_to_zero:
  - QObs(mm/d)

static_attributes:
  - elev_mean
  - area_gages2
  - slope_mean
  - p_mean
  - pet_mean
